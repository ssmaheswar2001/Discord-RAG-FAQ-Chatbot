{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c432e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment them & install the necessary packages\n",
    "# !pip install python-docx\n",
    "# !pip install langchain\n",
    "# !pip install sentence-transformers\n",
    "# !pip install pymongo\n",
    "# !pip install tf-keras\n",
    "# !pip install tiktoken\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be7aa7",
   "metadata": {},
   "source": [
    "### Step1: Setup Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8067926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c328b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "MONGODB_URI=os.environ.get(\"MONGODB_URI\")\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "mongodb_client = MongoClient(MONGODB_URI)\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    mongodb_client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc6191",
   "metadata": {},
   "source": [
    "### Step2: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abae59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fd803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from .docx\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    text = []\n",
    "    for para in doc.paragraphs:\n",
    "        if para.text.strip():\n",
    "            text.append(para.text.strip())\n",
    "    return \"\\n\".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703adbfa",
   "metadata": {},
   "source": [
    "### Step3: Chunk up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883d0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea02f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\", \"#\", \"##\", \"###\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be702322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk text using LangChain's RecursiveCharacterTextSplitter\n",
    "def get_chunk(text, chunk_size=200, chunk_overlap=30):\n",
    "    return splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda6b4f",
   "metadata": {},
   "source": [
    "### Step4: Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46fac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\surya\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ced7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all-MiniLM-L6-v2 (384d) - faster inference, good quality\n",
    "BAAI/bge-small-en-v1.5 (384d) - better semantic understanding\n",
    "sentence-transformers/all-mpnet-base-v2 (768d) - higher quality\n",
    "'''\n",
    "\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66dc1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings using Sentence Transformers\n",
    "def generate_embeddings(chunks):\n",
    "    embeddings = embedding_model.encode(chunks)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae496f78",
   "metadata": {},
   "source": [
    "# Step5: Ingest data int MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c21640",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"rag_chatbot\"\n",
    "COLLECTION_NAME = \"knowledge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b78f177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `COLLECTION_NAME` collection.\n",
    "collection = mongodb_client[DB_NAME][COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd8794e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 65, 'electionId': ObjectId('7fffffff000000000000026f'), 'opTime': {'ts': Timestamp(1752512775, 14), 't': 623}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1752512775, 14), 'signature': {'hash': b'[\\x1b\\x19\\xc7\\n\\xb0\\x11\\x8eU\\xaa\\xe3\\xd8\\xe2\\xbe\\x011\\xe4\\xb8\\x8c\\xca', 'keyId': 7461045087271649375}}, 'operationTime': Timestamp(1752512775, 14)}, acknowledged=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Bulk delete all existing records from the collection defined above\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7f3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_chunks_in_mongo(chunks, embeddings, source_doc):\n",
    "    # Batch insert for better performance\n",
    "    records = []\n",
    "    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "        record = {\n",
    "            \"source\": source_doc,\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk,\n",
    "            \"embedding\": embedding.tolist(),\n",
    "            \"chunk_length\": len(chunk)\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    # Bulk insert\n",
    "    if records:\n",
    "        collection.insert_many(records)\n",
    "    print(f\"✅ Ingested {len(chunks)} chunks from {source_doc} in MongoDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de281be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Process a single document\n",
    "def process_document(file_path):\n",
    "    print(f\"\\n🔹 Processing: {file_path}\")\n",
    "    text = extract_text_from_docx(file_path)\n",
    "    chunks = get_chunk(text)\n",
    "    embeddings = generate_embeddings(chunks)\n",
    "\n",
    "    store_chunks_in_mongo(chunks, embeddings, os.path.basename(file_path) )\n",
    "    \n",
    "    return chunks, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f97e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. List of your uploaded documents\n",
    "file_paths = [\n",
    "    r'Knowledge_Docs/AI Bootcamp Journey & Learning Path.docx',\n",
    "    r'Knowledge_Docs/Intern FAQ - AI Bootcamp.docx',\n",
    "    r'Knowledge_Docs/Training For AI Engineer Interns.docx'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17856f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Processing: Knowledge_Docs/AI Bootcamp Journey & Learning Path.docx\n",
      "✅ Ingested 13 chunks from AI Bootcamp Journey & Learning Path.docx in MongoDB.\n",
      "\n",
      "🔹 Processing: Knowledge_Docs/Intern FAQ - AI Bootcamp.docx\n",
      "✅ Ingested 41 chunks from Intern FAQ - AI Bootcamp.docx in MongoDB.\n",
      "\n",
      "🔹 Processing: Knowledge_Docs/Training For AI Engineer Interns.docx\n",
      "✅ Ingested 11 chunks from Training For AI Engineer Interns.docx in MongoDB.\n"
     ]
    }
   ],
   "source": [
    "# 6. Run the process for each file\n",
    "for file_path in file_paths:\n",
    "    process_document(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8423a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6875390c7a054d82fa3951a5'), 'source': 'AI Bootcamp Journey & Learning Path.docx', 'chunk_id': 0, 'text': 'Bootcamp Journey\\nUse this document as a high-level overview of your journey.\\nThis document will reference both these aspects:\\nTechnical Skills Development\\nCore ML/AI Concepts\\nGen AI & Data Engineering\\nMLOps & Deployment\\nProject-Based Learning\\nAgile Scrum Methodology\\nTeam Collaborations\\nReal-world Applications\\nProject Timeline\\nHere is a high-level time line of your 11-week journey.\\nWeek 1 - 11 Agenda for AI PM Bootcamp\\nWeek 1: Learning and Onboarding Study all the AI knowledge:\\nTraining for AI Engineers\\nTraining of AI Designer\\nEngineers: Working on Job Tracker or PM FAQ Chatbot', 'embedding': [-0.051575373858213425, 0.0025243167765438557, 0.055302925407886505, -0.07263786345720291, 0.00776576716452837, 0.06329257041215897, -0.004742173012346029, 0.04291272163391113, -0.032826587557792664, -0.049939848482608795, 0.038683027029037476, -0.03729373589158058, 0.05300578102469444, 0.004065188113600016, 0.0031883881893008947, -0.012413110584020615, -0.015629712492227554, -0.012431487441062927, -0.03620084375143051, 0.014892974868416786, 0.028096897527575493, -0.03575817123055458, -0.051832862198352814, -0.032798487693071365, 0.021842852234840393, 0.04401203617453575, -0.03382332623004913, -0.03397110849618912, -0.059066131711006165, -0.17511004209518433, -0.013697615824639797, -0.017149832099676132, 0.06017086282372475, 0.001828889362514019, 0.013421222567558289, 0.04626258462667465, -0.04235765337944031, 0.085829958319664, -0.0007027842220850289, 0.018907539546489716, 0.059255450963974, -0.023474425077438354, -0.02185933105647564, -0.039306603372097015, -0.003760679392144084, -0.07121752202510834, -0.036087289452552795, -0.04768889769911766, -0.0027137326542288065, -0.031873591244220734, 0.009776843711733818, -0.03365369886159897, 0.010179185308516026, 0.00013265133020468056, 0.013963657431304455, 0.05945781618356705, 0.0943920761346817, 0.021975670009851456, 0.07042372226715088, 0.06277889758348465, 0.006644966080784798, 0.03787437453866005, -0.24974249303340912, 0.09525127708911896, 0.052654165774583817, 0.024757862091064453, -0.07984831184148788, -0.009331305511295795, 0.04229668527841568, 0.05457431450486183, -0.08151836693286896, -0.0071211704052984715, 0.015772037208080292, 0.04565742611885071, 0.03482727333903313, -0.020849017426371574, -0.001864647725597024, -0.0330679677426815, 0.018420234322547913, 0.011553116142749786, -0.055995795875787735, -0.013049800880253315, -0.04893350228667259, -0.02830999344587326, -0.0747339278459549, -0.04126202315092087, 0.025962257757782936, -0.032098010182380676, 0.004153788555413485, -0.011919445358216763, -0.010123430751264095, -0.07718686759471893, -0.04610685259103775, 0.023446112871170044, -0.050114355981349945, -0.032083649188280106, 0.04060914367437363, -0.008869050070643425, -0.03637751564383507, 0.2332318127155304, -0.06308943778276443, 0.006714404560625553, 0.029706619679927826, -0.0014690352836623788, -0.013758426532149315, -0.03853193297982216, 0.014616587199270725, 0.00012859122944064438, -0.018982695415616035, -0.009796726517379284, -0.020486310124397278, -0.03922252729535103, 0.021155115216970444, -0.025066690519452095, 0.0013985926052555442, 0.010929886251688004, 0.037890758365392685, 0.023660186678171158, 0.010896108113229275, -0.008651312440633774, -0.002975697861984372, -0.018483014777302742, 0.046583786606788635, -0.04756678268313408, -0.03494807705283165, -0.06720245629549026, 0.07082048058509827, 0.08819318562746048, 0.01763819344341755, 0.00871798861771822, 0.07395518571138382, 0.008288432843983173, -0.06250029057264328, 0.0012984341010451317, 0.01968495175242424, -0.007292895577847958, 0.009886467829346657, -0.026843441650271416, -0.024832507595419884, 0.00046683798427693546, -0.020560473203659058, -0.028789153322577477, 0.03055434115231037, -0.10947159677743912, -0.027837954461574554, 0.12330002337694168, -0.017071545124053955, 0.06556205451488495, -0.042754702270030975, -0.000505302392411977, -0.06086841970682144, 0.022090312093496323, 0.006342960987240076, -0.03968874737620354, 0.013038234785199165, 0.02854440174996853, 0.06426655501127243, 0.037756796926259995, -0.0530349500477314, 0.022560281679034233, -0.0402449406683445, -0.06719375401735306, -0.028903307393193245, 0.13936443626880646, 0.07004838436841965, -0.11605262011289597, -0.002542399801313877, 0.008539075963199139, 0.046829938888549805, 0.007380831055343151, 0.032718475908041, 0.006940849591046572, -0.005153454840183258, 0.007942989468574524, 0.08453432470560074, -0.008385512046515942, -0.03557398542761803, 0.0032112153712660074, -0.0022391199599951506, 0.03247452899813652, 0.0434986874461174, -0.0750601589679718, -0.061517443507909775, 0.04703134670853615, 0.08002276718616486, -0.03381744399666786, 0.009676134213805199, -0.05175261199474335, 0.030059559270739555, 0.018108341842889786, -0.011187863536179066, 0.041804615408182144, -0.0016366994241252542, -0.0026700380258262157, -0.028322475031018257, -0.018702035769820213, -0.0029063003603368998, 0.004805999342352152, 0.014095902442932129, -0.019447514787316322, 0.013629025779664516, -0.005314177367836237, -0.03599967062473297, 0.04018021374940872, -0.019939551129937172, 0.022016791626811028, -0.020542167127132416, 0.009219257161021233, 0.055658064782619476, 0.016802093014121056, -0.05634909123182297, 0.007131289225071669, 0.057947684079408646, -0.012922811321914196, -0.016995349898934364, -0.019609520211815834, 0.004600068554282188, 0.021214166656136513, -0.012556676752865314, 0.08433838188648224, 0.003896912792697549, -0.010431469418108463, -0.024389011785387993, -0.21816805005073547, 0.03284236788749695, 0.02724684774875641, -0.022871680557727814, 0.010172024369239807, -0.00580761581659317, 0.036747951060533524, -0.06645338237285614, 0.02272649295628071, 0.0254216268658638, 0.13985544443130493, -0.06569357216358185, -0.006953008938580751, -0.014794662594795227, -0.027505235746502876, 0.03744339942932129, 0.016267072409391403, 0.045635998249053955, -0.03276379406452179, 0.04014694318175316, 0.0012417009565979242, 0.02881665900349617, -0.0300324447453022, -0.10077197104692459, -0.0014406545087695122, 0.005112913902848959, 0.18006397783756256, -0.006177954841405153, 0.012313568033277988, -0.02343929372727871, 0.026807481423020363, 0.007917162030935287, 0.015150779858231544, -0.13503508269786835, 0.052118320018053055, -0.02488371729850769, 0.048744991421699524, -0.006653765682131052, 0.015335612930357456, -0.04036536440253258, -0.03620306774973869, 0.0548471063375473, -0.003057025605812669, -0.11766313761472702, -0.055381231009960175, -0.055975571274757385, -0.06297563761472702, 0.004892860539257526, -0.04693922773003578, -0.001086481031961739, 0.009173906408250332, -0.05327613651752472, 0.017002888023853302, 0.022689729928970337, -0.012160644866526127, -0.03258883208036423, -0.10496091097593307, 0.03797037526965141, -0.050152428448200226, 0.05379544571042061, -0.004141082521528006, -0.048586782068014145, 0.016348719596862793, -0.027427611872553825, 0.04967954754829407, 0.014951098710298538, -0.01668839156627655, -0.019552601501345634, 0.05487971380352974, -0.05763652175664902, 0.00961883645504713, 0.06664974987506866, 0.004024808760732412, -0.013355410657823086, 0.07770180702209473, -0.014258564449846745, 0.0304216630756855, -0.016903335228562355, -0.00570633914321661, -0.02736417017877102, 0.03997218981385231, -0.05408840253949165, 0.019115161150693893, 0.03330588713288307, 0.032099563628435135, 0.027597950771450996, 0.03476381674408913, -0.004050719551742077, 0.07062345743179321, 0.026643693447113037, 0.006980006583034992, 0.0050070397555828094, -0.023314138874411583, -0.01441532839089632, 0.027014199644327164, 0.0057268752716481686, -0.27386942505836487, 0.06934702396392822, 0.054044321179389954, 0.08108390867710114, -0.03563684597611427, 0.0058828676119446754, 0.05190165713429451, 0.011333026923239231, -0.05046478286385536, 0.029157698154449463, 0.021497616544365883, 0.03460787609219551, 0.052862826734781265, -0.018737217411398888, 0.005833007395267487, 0.033545345067977905, 0.07347893714904785, -0.03934153541922569, 0.03806329891085625, -0.05434810370206833, -0.014865724369883537, 0.009145956486463547, 0.2017335593700409, -0.028177497908473015, 0.00882975198328495, 0.006360949017107487, -0.04424260929226875, 0.012446029111742973, 0.046395838260650635, -0.01514631137251854, 0.03600037097930908, 0.0009660421637818217, 0.09450200200080872, 0.002646914217621088, 0.03929082676768303, 0.06246490404009819, -0.017421791329979897, 0.036396656185388565, 0.011429700069129467, 0.020152537152171135, 0.00550997955724597, 0.012636943720281124, 0.002677052980288863, -0.014698703773319721, 0.09162845462560654, -0.04226139187812805, -0.052357129752635956, -0.06716897338628769, -0.0009344171267002821, 0.005235728342086077, -0.040217138826847076, -0.010215651243925095, -0.01834006793797016, 0.05369582399725914, 0.07854844629764557, 0.05737612396478653, 0.007294012233614922, -0.03624306246638298, -0.04074683040380478, -0.07839145511388779, 0.0030029830522835255, -0.01754256896674633, 0.009272289462387562, 0.004039468243718147, -0.01664287969470024], 'chunk_length': 583}\n"
     ]
    }
   ],
   "source": [
    "print(collection.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bccb21",
   "metadata": {},
   "source": [
    "### Step6: Create a vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5a53cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import create_index, check_index_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "515b3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c864b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_definition= {\n",
    "    \"name\": ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 384,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filter\",\n",
    "                \"path\": \"source\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a738a1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the vector_index index\n"
     ]
    }
   ],
   "source": [
    "# Use the `create_index` function from the `utils` module to create a vector search index with the above definition for the `collection` collection\n",
    "create_index(collection, ATLAS_VECTOR_SEARCH_INDEX_NAME, index_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5928c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_index index status: READY\n",
      "vector_index index definition: {'fields': [{'type': 'vector', 'path': 'embedding', 'numDimensions': 384, 'similarity': 'cosine'}, {'type': 'filter', 'path': 'source'}]}\n"
     ]
    }
   ],
   "source": [
    "# Use the `check_index_ready` function from the `utils` module to verify that the index was created and is in READY status before proceeding\n",
    "check_index_ready(collection, ATLAS_VECTOR_SEARCH_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455b63a",
   "metadata": {},
   "source": [
    "### Step7: Perform Vector Search on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0685dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(user_query: str, limit: int = 7, min_score: float = 0.7):\n",
    "    \"\"\"\n",
    "    Optimized vector search with filtering and caching\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode([user_query])[0].tolist()\n",
    "    \n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"embedding\",\n",
    "                \"numCandidates\": 50,  # Reduced for better performance\n",
    "                \"limit\": limit,  # Get more candidates for filtering\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"text\": 1,\n",
    "                \"source\": 1,\n",
    "                \"chunk_id\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$limit\": limit\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = list(collection.aggregate(pipeline))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37b47104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 20,\n",
       "  'text': '✅ Demonstrated strong engineering fundamentals\\n🎖 Recognition:\\n🏅 LinkedIn badge\\n🏅Team recognition post on LinkedIn\\n🏅 AI Engineer/ AI Designer Certification\\n🏅 Access to free job referrals to tech companies\\n🏅 Letter of recommendation from team lead\\n🏅 LinkedIn endorsement from the team lead\\n🏅 Priority access to  future bootcamp cohorts\\n🥉 Tier 3: AI Rising Star\\nTook initiative. Gained real-world experience.\\nCriteria:\\n✅ Participated in the entire project without quitting\\n✅ Making efforts to communicate with the team lead and team members\\n✅ Showed enthusiasm to grow and learn\\n🎖 Recognition:',\n",
       "  'score': 0.938530683517456},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 8,\n",
       "  'text': 'Week 4: All: Join Pitch Day where Product Mangers and Designers will demonstrate their Ai product ideas and High-Fidelity designs after user research and gathering Voice of the Customer feedback.\\nEngineers will then fill out a Google form:\\nSharing their tech stack years of experience\\nRanking their top 3 product idea choices\\nWant to be a Lead Engineer or not.\\nWeek 5-8: Work with your AI product teams to create an AI MVP.\\nLead Engineer: Help with System design conversations and setting up GitHub directory and local Git deployment.',\n",
       "  'score': 0.9374999403953552},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 25,\n",
       "  'text': 'Resources and Learning:\\nParticipants will have access to technical advisors and recommended courses to improve their AI skills. Dr. Nancy Li encourages continuous learning and upskilling in areas like AI and cloud computing. Here is the training doc for all interns.\\nEvaluation and Outcome:\\nThe technical assessment will determine who gets selected. The evaluation includes both the coding quality and the candidate’s ability to collaborate effectively within the team.',\n",
       "  'score': 0.9372713565826416},\n",
       " {'source': 'Training For AI Engineer Interns.docx',\n",
       "  'chunk_id': 0,\n",
       "  'text': 'Key Technical Knowledge For AI Engineers\\nBasic AI Concepts\\nMachine Learning: Systems learning patterns from data to improve performance.\\nHigh-level intro, types of ML,\\nDeep Learning: Utilizing neural networks with many layers to model complex patterns.\\nWhat is deep learning\\nMath behind deep learning\\nNatural Language Processing (NLP): A class of AIs aimed at processing and understanding human language.',\n",
       "  'score': 0.9353585839271545},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 23,\n",
       "  'text': 'Internship Structure:\\nThe internship is unpaid but offers valuable hands-on experience in AI product development. Participants will work alongside product managers (PMs) and other engineers to build real-life AI products.\\nThe teams consist of software developers, data scientists, and product managers. The internship includes working on tasks like voice of customer interviews, MVP development, and go-to-market strategies.\\nApplication and Selection Process:',\n",
       "  'score': 0.9331325888633728},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 2,\n",
       "  'text': 'https://youtu.be/5OZjUtUdbbI?si=iW_JL81H3fjLl0yn\\nJoin our first tech mentor session. Dates will be announced in the Discord channel. Our mentor will give you an overview of how to collaborate in a cross-functional team during the AI project and how to find tech resources. Here is the link to the onboarding and training guide for all interns. Here are the Youtube playlists training referenced in the training guide above.\\nEngineers’ Training Playlist\\nDesigners’ Training Playlist',\n",
       "  'score': 0.9325688481330872},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 22,\n",
       "  'text': '—------------------------------------------------------------------------------------------------------------------\\nAI Engineer Group Interview and FAQ\\n- PM Accelerator\\nOverview of the AI Engineer Internship Process:\\nIntroduction and Setup:\\nThe video begins with Dr. Nancy Li conducting a group interview for an AI engineer internship. Due to high demand, she explains how the Zoom meeting was initially limited to 100 participants but was later upgraded to accommodate more attendees.\\nInternship Structure:',\n",
       "  'score': 0.9314010143280029}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"AI engineering skills required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e343551c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'AI Bootcamp Journey & Learning Path.docx',\n",
       "  'chunk_id': 0,\n",
       "  'text': 'Bootcamp Journey\\nUse this document as a high-level overview of your journey.\\nThis document will reference both these aspects:\\nTechnical Skills Development\\nCore ML/AI Concepts\\nGen AI & Data Engineering\\nMLOps & Deployment\\nProject-Based Learning\\nAgile Scrum Methodology\\nTeam Collaborations\\nReal-world Applications\\nProject Timeline\\nHere is a high-level time line of your 11-week journey.\\nWeek 1 - 11 Agenda for AI PM Bootcamp\\nWeek 1: Learning and Onboarding Study all the AI knowledge:\\nTraining for AI Engineers\\nTraining of AI Designer\\nEngineers: Working on Job Tracker or PM FAQ Chatbot',\n",
       "  'score': 0.9556460976600647},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 0,\n",
       "  'text': 'Intern FAQ - AI Bootcamp\\nHere are the next steps (Intern Onboarding).\\nIF YOU DIDN’T watch the welcome and onboarding video by Dr. Nancy Li, make sure to watch it now. This is mandatory to know how to be successful during the internship.\\nJoin our Developer Discord server and complete your server onboarding process. Once you join the server will have pop-ups to guide you through the process.\\nThe first thing you should do after joining discord is to update your profile with your full name and linkedin url.  This is the main way everyone will communicate with you.',\n",
       "  'score': 0.9264770746231079},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 9,\n",
       "  'text': \"Week 9-10: Start testing the various functionalities. Designers would be very helpful here since they know the user's mindset the best.\\nNote: The Product Manager will create the main GitHub repository. The Lead Engineer on each team should help others who are not familiar with GitHub as well as help with System Design. When you have questions please reach out to the mentors during Office Hours.\\n—-----------------------------------------------------------------------------------------------------------------\\nAI PM Bootcamp FAQ\\n🧑\\u200d💻 Team Structure Overview\",\n",
       "  'score': 0.9234256744384766},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 20,\n",
       "  'text': '✅ Demonstrated strong engineering fundamentals\\n🎖 Recognition:\\n🏅 LinkedIn badge\\n🏅Team recognition post on LinkedIn\\n🏅 AI Engineer/ AI Designer Certification\\n🏅 Access to free job referrals to tech companies\\n🏅 Letter of recommendation from team lead\\n🏅 LinkedIn endorsement from the team lead\\n🏅 Priority access to  future bootcamp cohorts\\n🥉 Tier 3: AI Rising Star\\nTook initiative. Gained real-world experience.\\nCriteria:\\n✅ Participated in the entire project without quitting\\n✅ Making efforts to communicate with the team lead and team members\\n✅ Showed enthusiasm to grow and learn\\n🎖 Recognition:',\n",
       "  'score': 0.923291802406311},\n",
       " {'source': 'AI Bootcamp Journey & Learning Path.docx',\n",
       "  'chunk_id': 11,\n",
       "  'text': 'Week 2: Friday, February 7 @ 11am - Duration : 30 mins Session Theme: Q&A: General - (Session Canceled, No attendees)\\nWeek 3: Friday, February 14 @ 11am - Duration 1hr Session Theme: Prepping for Team Matching & I’m on a team, now what?  https://youtu.be/d7bCIwlXZsY\\nWeek 4: Friday, February 21 @ 10am - Duration 30 mins Session Theme: AI Product Lifecycle https://youtu.be/sc8g3RvwBBk\\nWeek 5: Friday, February 28 @ 11am - Duration 30 mins Session Theme: Outcome Mindset & Delivering Value  https://youtu.be/ADjjqyM1zP4',\n",
       "  'score': 0.9217227101325989},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 11,\n",
       "  'text': \"Key Recommendations\\nAt least 3 product managers per team to divide user research, roadmap, and GTM work\\nAt least 3 developers for faster development and technical redundancy\\nData scientists and designers are optional based on your product goals\\n📌 The more balanced and collaborative your team, the higher the chance of building a real, launch-ready product. Let us know if you'd like support building your team or scoping your idea!\\nCohort Schedule\\nThe below schedule is the full bootcamp schedule, All interns can attend the mentor office hours, NOT the group training for PMs.\",\n",
       "  'score': 0.9216023683547974},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 39,\n",
       "  'text': 'Do Interns have AI PM Bootcamp Kajabi access?\\n- No. Only PMs enrolled in the program have access to our course modules (Kajabi). Interns will have access to their own recorded training/session/files with the link/s that the PMA team will share.\\nExample:\\n- Recent AI Intern recorded training/ onboarding with Mentors Aishwarya Saad Shariff & Anil Thomas: https://youtu.be/O0WJ1LTqhAY\\n- Intern Onboarding, training, AI course and guide document: https://docs.google.com/document/d/18O8Xpbognhi3GYJeHDYbBRHGAl5-a4DL/edit?usp=sharing&ouid=100574353221996474859&rtpof=true&sd=true',\n",
       "  'score': 0.9198811054229736}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"Bootcamp Journey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "732a09eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 16,\n",
       "  'text': \"Cohort #5 = Jun-23-2025  - Sep-12-2025\\nCohort #6 = Sept-15-2025  - Nov-28-2025\\n🧩 Team Matching Process\\n🔹 Group Team Match (Week 4)\\nDuring this phase, students will:\\nFill out a team match form detailing their background, skills, and interests\\nAttend a Zoom team match call where PMs will pitch product ideas\\nEngineers will then fill out a Google form:\\nSharing their tech stack years of experience\\nRanking their top 3 product idea choices\\nWant to be a Lead Engineer or not.\\nTeams will be formed based on mutual interest, project scope, and complementary skills\\n📹 Example: Cohort 3's  team match video.\",\n",
       "  'score': 0.9504494667053223},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 33,\n",
       "  'text': '—------------------------------------------------------------------------------------------------------------------\\nAdditional Intern Questions:\\nWhat happens in situations when my OPT/CPT dates are 1-month into the program and ends before the next cohort?\\nExample: I’m interested in joining Cohort 5:\\nCohort #5 = Jun-23-2025  - Sep-12-2025\\nCohort #6 = Sept-15-2025  - Nov-28-2025\\nBut my OPT/CPT will only allow me to have Start Date = June 23rd and End Date = August 8th.',\n",
       "  'score': 0.9500331878662109},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 11,\n",
       "  'text': \"Key Recommendations\\nAt least 3 product managers per team to divide user research, roadmap, and GTM work\\nAt least 3 developers for faster development and technical redundancy\\nData scientists and designers are optional based on your product goals\\n📌 The more balanced and collaborative your team, the higher the chance of building a real, launch-ready product. Let us know if you'd like support building your team or scoping your idea!\\nCohort Schedule\\nThe below schedule is the full bootcamp schedule, All interns can attend the mentor office hours, NOT the group training for PMs.\",\n",
       "  'score': 0.9372768402099609},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 15,\n",
       "  'text': 'August 24, Sunday 11am EST- 12pm EST - Office hours with Apoorva Joshi\\nWeek 10 Nail Your AI PM Interviews\\nAugust 25, Monday 8pm EST - 10pm EST, Group Coaching and Office Hours with Dr. Nancy Li\\nAugust 31, Sunday 11am EST- 12pm EST - Office hours with Apoorva Joshi\\nWeek 11 GTM - Drive users and engagement of your Al Project\\nSep 1st, Monday 8pm EST - 10pm EST, Group Coaching and Office Hours with Dr. Nancy Li\\nSep 4, Thursday, Group Project Demo: Showcase your product with a demo. Get feedback from AI advisors\\nCurrent and upcoming cohort duration\\nCohort #5 = Jun-23-2025  - Sep-12-2025',\n",
       "  'score': 0.9372323155403137},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 34,\n",
       "  'text': 'Reason: The university has informed me that they cannot approve the current dates listed in the offer letter, as the internship must conclude before the start of the Fall 2025 semester. According to their guidelines, the final allowable date for the internship is August 8, 2025..\\nCan I still join a cohort, but not tell my university?  - Can I get in trouble for this situation?\\nAnswer: If your CPT/OPT date is within 1 week or so around our cohort date. It’s fine. If it cuts off in the middle of the cohort. We have to move you to the future cohort.',\n",
       "  'score': 0.9352771043777466},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 1,\n",
       "  'text': 'Please introduce yourself in the #networking channel and post your techstack in the #techstack channel\\nWatch past cohort demos [MANDATORY]\\nSummary of Cohort 1 and 2 Demo\\nhttps://youtu.be/S69147JbQpU?si=p0fHjqO7tTlyUHTB\\nExample of Cohort 3 Demo (highly recommended)\\nhttps://youtu.be/5OZjUtUdbbI?si=iW_JL81H3fjLl0yn',\n",
       "  'score': 0.9316794872283936},\n",
       " {'source': 'Intern FAQ - AI Bootcamp.docx',\n",
       "  'chunk_id': 37,\n",
       "  'text': '**2. Offer Letter Timing**\\nWe are able to revise your offer letter based on your CPT/OPT dates. However, we ask that your start and end dates align as closely as possible with your assigned cohort timeline. A 1–2 week delay is acceptable if there are processing delays, but please keep us informed and send us any updated dates as soon as possible.\\n**3. E-Verify Requirements**',\n",
       "  'score': 0.9295105338096619}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"Cohort Schedule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589d874",
   "metadata": {},
   "source": [
    "### Step8: Build the RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "673c4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "701b43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT=os.environ.get(\"OPENAI_ENDPOINT\")\n",
    "API_KEY=os.environ.get(\"OPENAI_KEY\")\n",
    "MODEL_NAME=os.environ.get(\"MODEL_NAME\")\n",
    "API_VERSION=os.environ.get(\"API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c583e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91409175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a chat prompt that includes the user query and retrieved context.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "        str: The chat prompt string.\n",
    "    \"\"\"\n",
    "    # Retrieve the most relevant documents for the `user_query` using the `vector_search` function defined in Step 7\n",
    "    context = vector_search(user_query)\n",
    "    # Join the retrieved documents into a single string, where each document is separated by two new lines (\"\\n\\n\")\n",
    "    context = \"\\n\\n\".join([doc.get('text') for doc in context])\n",
    "    # print(context)\n",
    "    # Prompt consisting of the question and relevant context to answer it\n",
    "    prompt = f\"Answer the question based only on the following context. If the context is empty, say I DON'T KNOW\\n\\nContext:\\n{context}\\n\\nQuestion:{user_query}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9adc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define a function to answer user queries\n",
    "def generate_answer(user_query: str) -> None:\n",
    "    \"\"\"\n",
    "    Generate an answer to the user query.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The user's query string.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = create_prompt(user_query)\n",
    "    # print(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful Q&A assistant.\",},\n",
    "            {\"role\": \"user\",\"content\": prompt,}\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        model=MODEL_NAME\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb44f7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two team matching sessions are as follows:\n",
      "\n",
      "1. Week 2: Product Managers will pitch to Designers to join their AI product idea.\n",
      "2. Week 4: Product Managers and Designers will create High-Fidelity designs to pitch their AI product idea to Engineers/Data Scientists.\n"
     ]
    }
   ],
   "source": [
    "generate_answer('2 Team matching sessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d78e56c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each team is formed from participants in the PM Accelerator Program and typically includes:\n",
      "\n",
      "- Product Managers – Responsible for business case development, voice of customer interviews, and market research\n",
      "- Developers – Execute the technical build\n",
      "- (Optional) Data Scientists & Designers – Added as needed, based on project complexity\n",
      "\n",
      "Typical team size: 8–10 members. Larger-scope projects may be assigned bigger teams. Teams with multiple PMs and developers tend to launch more ambitious, successful products.\n"
     ]
    }
   ],
   "source": [
    "generate_answer('Team Structure Overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "487b8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort #5 runs from June 23, 2025, to September 12, 2025. Following that, Cohort #6 is scheduled from September 15, 2025, to November 28, 2025.\n"
     ]
    }
   ],
   "source": [
    "generate_answer('Cohort Schedule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e844b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
